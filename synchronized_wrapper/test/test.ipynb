{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mujoco wrappers test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from synchronized_wrapper.mujoco_wrapper import mujoco_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "action_space\n",
      "1.0 -1.0 (17,)\n",
      "0.4 -0.4 (17,)\n",
      "observation_space\n",
      "inf -inf (1880,)\n",
      "inf -inf (376,)\n"
     ]
    }
   ],
   "source": [
    "game_id = 'HumanoidStandup-v2'\n",
    "stack = 5\n",
    "env = mujoco_env(game_id, stack=stack)\n",
    "gym_env = gym.make(game_id)\n",
    "\n",
    "print('action_space')\n",
    "print(env.action_space.high[0], env.action_space.low[0], env.action_space.shape)\n",
    "print(gym_env.action_space.high[0], gym_env.action_space.low[0], gym_env.action_space.shape) \n",
    "\n",
    "print('observation_space')\n",
    "print(env.observation_space.high[0], env.observation_space.low[0], env.observation_space.shape)\n",
    "print(gym_env.observation_space.high[0], gym_env.observation_space.low[0], gym_env.observation_space.shape)\n",
    "assert env.observation_space.shape[0] == stack * gym_env.observation_space.shape[0]\n",
    "\n",
    "assert env.observation_space.contains(env.reset())\n",
    "while True:\n",
    "    s, r, d, _ = env.step(np.random.uniform(low=-1.0, high=1.0, size=env.action_space.shape[0]))\n",
    "    assert env.observation_space.contains(s)\n",
    "    if d:\n",
    "        break\n",
    "\n",
    "env.close()\n",
    "gym_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Atari wrappers test (just test for RewardClipEnv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from synchronized_wrapper.atari_wrapper import atari_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'real_reward': 0.0, 'was_real_done': False, 'ale.lives': 2}\n",
      "{'real_reward': 0.0, 'was_real_done': False, 'ale.lives': 1}\n",
      "{'real_reward': 0.0, 'was_real_done': True, 'ale.lives': 0}\n",
      "5.0 220.0\n"
     ]
    }
   ],
   "source": [
    "game_id = 'BeamRiderNoFrameskip-v4'\n",
    "env = atari_env(game_id)\n",
    "\n",
    "allowed_actions = list(range(env.action_space.n))\n",
    "\n",
    "env.reset()\n",
    "reward = 0\n",
    "real_reward = 0\n",
    "while True:\n",
    "    s, r, d, info = env.step(np.random.choice(allowed_actions))\n",
    "    \n",
    "    assert 'was_real_done' in info\n",
    "    assert 'real_reward' in info\n",
    "    assert r in [-1.0, 0.0, 1.0]\n",
    "    \n",
    "    reward += r\n",
    "    real_reward += info['real_reward']\n",
    "    if d:\n",
    "        print(info)\n",
    "        if info['was_real_done']:\n",
    "            print(reward, real_reward)\n",
    "            break\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Agent test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from synchronized_wrapper.atari_wrapper import get_atari_env_fn\n",
    "from synchronized_wrapper.mujoco_wrapper import get_mujoco_env_fn\n",
    "from synchronized_wrapper.agent import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process STDOUT and STDERR is being redirected to /tmp/raylogs/.\n",
      "Waiting for redis server at 127.0.0.1:36039 to respond...\n",
      "Waiting for redis server at 127.0.0.1:49320 to respond...\n",
      "Starting local scheduler with the following resources: {'CPU': 32, 'GPU': 4}.\n",
      "\n",
      "======================================================================\n",
      "View the web UI at http://localhost:8891/notebooks/ray_ui92588.ipynb?token=20fa1e365010bb53be5ba23ee6dc093e3bf09af8d660de2f\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All subagents are ready! \n",
      "action_space\n",
      "int32 <class 'gym.spaces.multi_discrete.MultiDiscrete'>\n",
      "observation_space\n",
      "1.0 0.0 (8, 84, 84, 4) float32\n",
      "{}\n",
      "All subagents are ready! \n",
      "[7.]\n",
      "{b'SubAgent-5': {b'length': 458, b'reward': 7.0}}\n",
      "[6.]\n",
      "{b'SubAgent-0': {b'length': 541, b'reward': 6.0}}\n",
      "[7.]\n",
      "{b'SubAgent-7': {b'length': 556, b'reward': 7.0}}\n",
      "[5.]\n",
      "{b'SubAgent-6': {b'length': 574, b'reward': 5.0}}\n",
      "[5.]\n",
      "{b'SubAgent-4': {b'length': 580, b'reward': 5.0}}\n",
      "[1.]\n",
      "{b'SubAgent-5': {b'length': 230, b'reward': 1.0}}\n",
      "[8. 0.]\n",
      "{b'SubAgent-0': {b'length': 205, b'reward': 0.0}, b'SubAgent-1': {b'length': 746, b'reward': 8.0}}\n",
      "[2.]\n",
      "{b'SubAgent-4': {b'length': 199, b'reward': 2.0}}\n",
      "[2.]\n",
      "{b'SubAgent-6': {b'length': 236, b'reward': 2.0}}\n",
      "[5.]\n",
      "{b'SubAgent-2': {b'length': 862, b'reward': 5.0}}\n",
      "[4.]\n",
      "{b'SubAgent-7': {b'length': 378, b'reward': 4.0}}\n",
      "[1.]\n",
      "{b'SubAgent-0': {b'real_reward': 308.0, b'real_length': 963, b'length': 217, b'reward': 1.0}}\n"
     ]
    }
   ],
   "source": [
    "env_fn = get_atari_env_fn('BeamRiderNoFrameskip-v4')\n",
    "num_agents = 8\n",
    "\n",
    "env = Agent(num_agents=num_agents, env_fn=env_fn, basename='test')\n",
    "\n",
    "print('action_space')\n",
    "print(env.action_space.nvec.dtype, type(env.action_space))\n",
    "\n",
    "print('observation_space')\n",
    "assert env.observation_space.shape == (num_agents, 84, 84, 4)\n",
    "print(env.observation_space.high[0,0,0,0], env.observation_space.low[0,0,0,0], env.observation_space.shape, env.observation_space.dtype)\n",
    "\n",
    "assert env.reset().shape == (num_agents, 84, 84, 4)\n",
    "s, r, d, info = env.step(env.action_space.sample())\n",
    "assert s.shape == (num_agents, 84, 84, 4)\n",
    "assert r.shape == (num_agents,)\n",
    "assert d.shape == (num_agents,) and d.dtype == np.bool\n",
    "print(info)\n",
    "\n",
    "env.close()\n",
    "\n",
    "env = Agent(num_agents=num_agents, env_fn=env_fn, basename='test')\n",
    "env.reset()\n",
    "\n",
    "reward = np.zeros(num_agents)\n",
    "for i in range(1000):\n",
    "    s, r, d, info = env.step(env.action_space.sample())\n",
    "    reward += r\n",
    "    if d.any():\n",
    "        print(reward[d])\n",
    "        print(info)\n",
    "        reward[d] = 0.0\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All subagents are ready! \n",
      "[3.]\n",
      "{b'SubAgent-2': {b'real_reward': 132.0, b'length': 854, b'reward': 3.0}}\n",
      "[3.]\n",
      "{b'SubAgent-0': {b'real_reward': 132.0, b'length': 1009, b'reward': 3.0}}\n",
      "[3.]\n",
      "{b'SubAgent-6': {b'real_reward': 132.0, b'length': 1051, b'reward': 3.0}}\n",
      "[4.]\n",
      "{b'SubAgent-5': {b'real_reward': 176.0, b'length': 1074, b'reward': 4.0}}\n",
      "[8.]\n",
      "{b'SubAgent-4': {b'real_reward': 352.0, b'length': 1332, b'reward': 8.0}}\n",
      "[7.]\n",
      "{b'SubAgent-7': {b'real_reward': 308.0, b'length': 1389, b'reward': 7.0}}\n",
      "[11.]\n",
      "{b'SubAgent-3': {b'real_reward': 484.0, b'length': 1565, b'reward': 11.0}}\n",
      "[9.]\n",
      "{b'SubAgent-1': {b'real_reward': 396.0, b'length': 1740, b'reward': 9.0}}\n",
      "[4.]\n",
      "{b'SubAgent-6': {b'real_reward': 176.0, b'length': 898, b'reward': 4.0}}\n"
     ]
    }
   ],
   "source": [
    "from synchronized_wrapper.atari_wrapper import get_eval_atari_env_fn\n",
    "from synchronized_wrapper.atari_wrapper import RewardClipEnv\n",
    "\n",
    "fn = get_eval_atari_env_fn('BeamRiderNoFrameskip-v4')\n",
    "env_fn = lambda :RewardClipEnv(fn())\n",
    "\n",
    "env = Agent(num_agents=num_agents, env_fn=env_fn, basename='test')\n",
    "env.reset()\n",
    "\n",
    "reward = np.zeros(num_agents)\n",
    "for i in range(2000):\n",
    "    s, r, d, info = env.step(env.action_space.sample())\n",
    "    reward += r\n",
    "    if d.any():\n",
    "        print(reward[d])\n",
    "        print(info)\n",
    "        reward[d] = 0.0\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "All subagents are ready! \n",
      "action_space\n",
      "1.0 -1.0 (8, 17)\n",
      "observation_space\n",
      "inf -inf (8, 1504)\n",
      "{}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "All subagents are ready! \n",
      "[33197.5725523  32923.98087056 31035.49105128 34029.08147479\n",
      " 33604.92008781 33772.64100539 35806.21236894 32779.54982335]\n",
      "{b'SubAgent-2': {b'length': 1000, b'reward': 33197.572552298014}, b'SubAgent-6': {b'length': 1000, b'reward': 33772.641005386075}, b'SubAgent-3': {b'length': 1000, b'reward': 35806.21236893569}, b'SubAgent-5': {b'length': 1000, b'reward': 33604.92008781324}, b'SubAgent-4': {b'length': 1000, b'reward': 31035.491051278193}, b'SubAgent-0': {b'length': 1000, b'reward': 34029.081474787425}, b'SubAgent-7': {b'length': 1000, b'reward': 32779.54982334551}, b'SubAgent-1': {b'length': 1000, b'reward': 32923.98087055517}}\n"
     ]
    }
   ],
   "source": [
    "num_agents = 8\n",
    "game_id = 'HumanoidStandup-v2'\n",
    "env_fn = get_mujoco_env_fn(game_id)\n",
    "\n",
    "from synchronized_wrapper.mujoco_wrapper import mujoco_env\n",
    "gym_env = mujoco_env(game_id, stack=4)\n",
    "env = Agent(num_agents=num_agents, env_fn=env_fn, basename='test')\n",
    "\n",
    "print('action_space')\n",
    "print(env.action_space.high[0][0], env.action_space.low[0][0], env.action_space.shape)\n",
    "assert (env.action_space.high[0] == gym_env.action_space.high).all()\n",
    "assert (env.action_space.low[0] == gym_env.action_space.low).all()\n",
    "assert env.action_space.shape == (num_agents, *gym_env.action_space.shape)\n",
    "\n",
    "print('observation_space')\n",
    "print(env.observation_space.high[0][0], env.observation_space.low[0][0], env.observation_space.shape)\n",
    "assert (env.observation_space.high[0] == gym_env.observation_space.high).all()\n",
    "assert (env.observation_space.low[0] == gym_env.observation_space.low).all()\n",
    "assert env.observation_space.shape == (num_agents, *gym_env.observation_space.shape)\n",
    "\n",
    "gym_env.close()\n",
    "\n",
    "assert env.observation_space.contains(env.reset())\n",
    "s, r, d, info = env.step(env.action_space.sample())\n",
    "assert env.observation_space.contains(s)\n",
    "assert r.shape == (num_agents,)\n",
    "assert d.shape == (num_agents,) and d.dtype == np.bool\n",
    "print(info)\n",
    "\n",
    "env.close()\n",
    "\n",
    "env = Agent(num_agents=num_agents, env_fn=env_fn, basename='test')\n",
    "env.reset()\n",
    "\n",
    "reward = np.zeros(num_agents)\n",
    "for i in range(1000):\n",
    "    s, r, d, info = env.step(env.action_space.sample())\n",
    "    reward += r\n",
    "    if d.any():\n",
    "        print(reward[d])\n",
    "        print(info)\n",
    "        reward[d] = 0.0\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "multiprocessing test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "All subagents are ready! \n",
      "[36885.07160586 34888.6535089  32893.8788857  32548.53548361\n",
      " 31493.12474715 30692.2186922  32721.54136934 32904.92866246]\n",
      "{b'SubAgent-2': {b'length': 1000, b'reward': 32548.53548360885}, b'SubAgent-6': {b'length': 1000, b'reward': 32721.54136934481}, b'SubAgent-5': {b'length': 1000, b'reward': 30692.218692201062}, b'SubAgent-4': {b'length': 1000, b'reward': 31493.12474714508}, b'SubAgent-3': {b'length': 1000, b'reward': 34888.653508895986}, b'SubAgent-0': {b'length': 1000, b'reward': 32893.87888569827}, b'SubAgent-7': {b'length': 1000, b'reward': 32904.92866246142}, b'SubAgent-1': {b'length': 1000, b'reward': 36885.07160585759}}\n"
     ]
    }
   ],
   "source": [
    "num_agents = 8\n",
    "game_id = 'HumanoidStandup-v2'\n",
    "env_fn = get_mujoco_env_fn(game_id)\n",
    "\n",
    "env = Agent(num_agents=num_agents, env_fn=env_fn, basename='test', backend='multiprocessing')\n",
    "\n",
    "env.reset()\n",
    "reward = np.zeros(num_agents)\n",
    "for i in range(1000):\n",
    "    s, r, d, info = env.step(env.action_space.sample())\n",
    "    reward += r\n",
    "    if d.any():\n",
    "        print(reward[d])\n",
    "        print(info)\n",
    "        reward[d] = 0.0\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
